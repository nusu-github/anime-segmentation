# Anime Segmentation Training Configuration
# ==========================================
#
# Uses AnimeSegmentationDataModule to load skytnt/anime-segmentation dataset.
#
# Setup:
#   1. Download the dataset first:
#      python scripts/download_anime_segmentation.py
#
#   2. Train:
#      python -m anime_segmentation.training.train fit --config configs/anime_segmentation.yaml

seed_everything: 42

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  max_epochs: 120
  accelerator: auto
  devices: auto
  precision: bf16-mixed
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  log_every_n_steps: 50
  check_val_every_n_epoch: 1

  # Logging
  logger:
    class_path: lightning.pytorch.loggers.CSVLogger
    init_args:
      save_dir: ckpts/
      name: anime_seg_logs

# =============================================================================
# Model Configuration
# =============================================================================
model:
  # Backbone
  bb_name: caformer_s18
  bb_pretrained: true

  # Decoder architecture
  out_ref: true
  ms_supervision: true
  dec_ipt: true
  dec_ipt_split: true
  cxt_num: 3
  mul_scl_ipt: cat
  dec_att: ASPPDeformable
  squeeze_block: BasicDecBlk_x1
  dec_blk: BasicDecBlk
  lat_blk: BasicLatBlk
  dec_channels_inter: fixed
  use_norm: true

  # Optimizer
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 0.01

  scheduler_interval: epoch

  # Loss weights (with ContourLoss enabled for boundary fidelity)
  lambdas_pix:
    bce: 30.0
    iou: 0.5
    ssim: 10.0
    cnt: 5.0  # Boundary loss for hair strands and thin contours
  lambdas_cls:
    ce: 5.0

# =============================================================================
# Data Configuration - AnimeSegmentationDataModule
# =============================================================================
data:
  class_path: anime_segmentation.training.datamodule.AnimeSegmentationDataModule
  init_args:
    # Path to dataset (download first with scripts/download_anime_segmentation.py)
    data_root: datasets/anime-segmentation

    # Split configuration
    val_ratio: 0.1  # 10% for validation when auto-splitting

    # DataLoader settings
    size: [1024, 1024]
    batch_size: 8
    num_workers: 4
    pin_memory: true

    # Augmentation settings
    hflip_prob: 0.5
    rotation_degrees: 10.0
    color_jitter: true
    color_jitter_brightness: 0.2
    color_jitter_contrast: 0.2
    color_jitter_saturation: 0.2
    color_jitter_hue: 0.1

# =============================================================================
# Callbacks
# =============================================================================
checkpoint:
  dirpath: ckpts/
  filename: "anime_seg_epoch_{epoch}"
  save_top_k: 3
  monitor: val/loss
  mode: min
  save_last: true

lr_monitor:
  logging_interval: epoch

finetune:
  finetune_last_epochs: -40

early_stopping:
  monitor: val/loss
  patience: 30
  mode: min

visualization:
  num_samples: 4
  log_every_n_epochs: 1
  max_resolution: 512

# Backbone freezing - only recommended for DINO backbones
# backbone_freeze:
#   unfreeze_at_epoch: 10
#   backbone_lr_scale: 0.1

accumulate_grad:
  scheduling:
    0: 4
    10: 1

on_exception_checkpoint:
  dirpath: ckpts/
  filename: on_exception
