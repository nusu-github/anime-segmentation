# B1 Output Refinement Experiment Variant
# ========================================
# Configuration for output refinement training with intermediate supervision.
# This setup uses a pre-trained GT encoder for feature matching.
#
# Usage:
#   python -m ibis_net.train_cli fit --config configs/base.yaml --config configs/experiments/b1_outref.yaml
#
# Prerequisites:
#   1. Train GT encoder first (or use pre-trained checkpoint)
#   2. This config enables intermediate supervision for output refinement
#
# This variant uses:
# - ISNetDIS with intermediate supervision
# - GT encoder for feature matching
# - MSE feature loss mode

model:
  init_args:
    # Enable intermediate supervision
    interm_sup: true

    # GT encoder for feature matching
    gt_encoder:
      class_path: ibis_net.models.ISNetGTEncoder
      init_args:
        in_ch: 3
        out_ch: 1

    # Feature matching loss mode
    fs_loss_mode: MSE

    # Optimizer settings
    optimizer:
      class_path: torch.optim.Adam
      init_args:
        lr: 0.001
        betas: [0.9, 0.999]
        weight_decay: 0.0

data:
  # Default augmentation for output refinement
  aug_preset_train: default

  # Standard batch size
  batch_size_train: 8
  batch_size_valid: 1

trainer:
  # Monitor maxF metric for refinement training
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val_maxF
        mode: max
        save_top_k: 1
        save_last: true
        every_n_train_steps: 2000
        filename: "b1_outref-{epoch}-{val_maxF:.4f}"

    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_maxF
        patience: 20
        mode: max
        verbose: true
