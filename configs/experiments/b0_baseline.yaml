# B0 Baseline Experiment Variant
# ===============================
# IS-Net baseline configuration with FS loss and hflip-only augmentation.
# This matches the original IS-Net/DIS paper training setup and provides
# a reference point for comparing IBIS-Net model variants.
#
# Prerequisites:
#   Train GT encoder first:
#     python -m ibis_net.train_cli fit --config configs/base.yaml --config configs/experiments/gt_encoder_train.yaml
#
# Usage:
#   python -m ibis_net.train_cli fit \
#     --config configs/base.yaml \
#     --config configs/experiments/b0_baseline.yaml \
#     --model.init_args.gt_encoder.init_args.ckpt_path=saved_models/gt_encoder/last.ckpt
#
# This variant uses:
# - Standard ISNetDIS architecture
# - Intermediate supervision with GT encoder (FS loss)
# - Horizontal flip only augmentation (DIS paper default)

model:
  init_args:
    # Enable intermediate supervision (FS loss)
    interm_sup: true
    fs_loss_mode: MSE

    # GT encoder for feature matching
    gt_encoder:
      class_path: ibis_net.models.ISNetGTEncoder
      init_args:
        in_ch: 1
        out_ch: 1
        # Set checkpoint path via CLI:
        # --model.init_args.gt_encoder.init_args.ckpt_path=saved_models/gt_encoder/last.ckpt

    # Standard optimizer settings
    optimizer:
      class_path: torch.optim.Adam
      init_args:
        lr: 0.001
        betas: [0.9, 0.999]
        weight_decay: 0.0

data:
  # Horizontal flip only (DIS paper default)
  aug_preset_train: hflip_only

  # Standard batch size
  batch_size_train: 8
  batch_size_valid: 1

trainer:
  # Output directory for B0 baseline
  default_root_dir: saved_models/b0_baseline/

  # Monitor validation metrics
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val_maxF
        mode: max
        save_top_k: 1
        save_last: true
        every_n_train_steps: 2000
        filename: "b0_baseline-{epoch}-{val_maxF:.4f}"

    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_maxF
        patience: 20
        mode: max
        verbose: true
