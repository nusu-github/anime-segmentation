# BiRefNet Training Configuration
# ================================
#
# Usage:
#   python -m anime_segmentation.training.train fit --config configs/birefnet_default.yaml
#
# Override settings on command line:
#   python -m anime_segmentation.training.train fit \
#       --config configs/birefnet_default.yaml \
#       --trainer.max_epochs 200 \
#       --data.batch_size 16

seed_everything: 42

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  max_epochs: 120
  accelerator: auto
  devices: auto
  precision: bf16-mixed
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  log_every_n_steps: 50
  check_val_every_n_epoch: 1

  # Logging
  logger:
    class_path: lightning.pytorch.loggers.CSVLogger
    init_args:
      save_dir: ckpts/
      name: logs

# =============================================================================
# Model Configuration
# =============================================================================
model:
  # Backbone
  bb_name: convnext_atto
  bb_pretrained: true

  # Decoder architecture
  out_ref: true
  ms_supervision: true
  dec_ipt: true                    # Decoder input projection
  dec_ipt_split: true              # Split mode for input projection
  cxt_num: 3                       # Context feature count (0-3)
  mul_scl_ipt: cat                 # Multi-scale input fusion: "", "add", "cat"
  dec_att: ASPPDeformable          # Decoder attention: "", "ASPP", "ASPPDeformable"
  squeeze_block: BasicDecBlk_x1    # Squeeze block: "", "BasicDecBlk_x1", "ResBlk_x4"
  dec_blk: BasicDecBlk             # Decoder block type: "BasicDecBlk", "ResBlk"
  lat_blk: BasicLatBlk             # Lateral block type: "BasicLatBlk"
  dec_channels_inter: fixed        # Decoder intermediate channels: "fixed", "adap"
  use_norm: true                   # Use normalization layers

  # Auxiliary classification (disabled by default)
  # auxiliary_classification: true
  # num_classes: 225  # Required when auxiliary_classification is true

  # Activation (default: ReLU)
  # act_layer: gelu  # relu, gelu, swish
  # act_kwargs:
  #   inplace: true

  # Optimizer - any torch.optim optimizer can be used
  # Examples:
  #   torch.optim.Adam, torch.optim.AdamW, torch.optim.SGD, torch.optim.RMSprop
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 0.01

  # Scheduler - any torch.optim.lr_scheduler can be used (or set to null)
  # Examples:
  #   torch.optim.lr_scheduler.CosineAnnealingLR
  #   torch.optim.lr_scheduler.StepLR
  #   torch.optim.lr_scheduler.MultiStepLR
  #   torch.optim.lr_scheduler.OneCycleLR (set scheduler_interval: step)
  scheduler:
    class_path: torch.optim.lr_scheduler.CosineAnnealingLR
    init_args:
      T_max: 120 # Should match trainer.max_epochs
      eta_min: 1e-6
  scheduler_interval: epoch # 'epoch' or 'step'

  # Loss weights
  lambdas_pix:
    bce: 30.0
    iou: 0.5
    ssim: 10.0
    # Additional loss options (set to 0.0 to disable):
    # iou_patch: 0.5    # Patch-based IoU loss
    # mae: 30.0         # Mean Absolute Error
    # mse: 30.0         # Mean Squared Error
    # reg: 100.0        # Regularization
    # cnt: 5.0          # Contour loss
    # structure: 5.0    # Structure loss
  lambdas_cls:
    ce: 5.0

  # torch.compile settings (optional)
  # compile: true
  # compile_mode: default           # default, reduce-overhead, max-autotune, max-autotune-no-cudagraphs
  # compile_fullgraph: false        # Compile as a single graph
  # compile_dynamic: null           # null=auto, true=dynamic shapes, false=static shapes
  # compile_backend: inductor       # Backend: inductor, eager, aot_eager, etc.

# =============================================================================
# Data Configuration
# =============================================================================
data:
  class_path: anime_segmentation.training.datamodule.BiRefNetDataModule
  init_args:
    data_root: DIS5K # REQUIRED: Change this to your dataset path
    training_sets:
      - DIS-TR # Example: DIS5K training set
    validation_sets:
      - DIS-VD # Example: DIS5K validation set
    test_sets: []
    size: [1024, 1024]
    batch_size: 8
    num_workers: 4
    pin_memory: true

    # Augmentation settings
    hflip_prob: 0.5
    rotation_degrees: 10.0
    color_jitter: true
    color_jitter_brightness: 0.2
    color_jitter_contrast: 0.2
    color_jitter_saturation: 0.2
    color_jitter_hue: 0.1

# =============================================================================
# Callbacks
# =============================================================================
trainer:
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: ckpts/
        filename: "epoch_{epoch}"
        save_top_k: 3
        monitor: val/loss
        mode: min
        save_last: true

    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch

    - class_path: anime_segmentation.training.callbacks.FinetuneCallback
      init_args:
        finetune_last_epochs: -40  # Start fine-tuning 40 epochs before end

    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val/loss
        patience: 30
        mode: min

    - class_path: anime_segmentation.training.callbacks.VisualizationCallback
      init_args:
        num_samples: 4
        log_every_n_epochs: 1
        max_resolution: 512  # Max resolution for visualization (null to keep original)

    # Backbone freezing - only recommended for DINO backbones
    # - class_path: anime_segmentation.training.callbacks.BackboneFreezeCallback
    #   init_args:
    #     unfreeze_at_epoch: 10
    #     backbone_lr_scale: 0.1

    - class_path: lightning.pytorch.callbacks.GradientAccumulationScheduler
      init_args:
        scheduling:
          0: 4   # Accumulate 4 steps for first 10 epochs
          10: 1  # No accumulation after epoch 10

    - class_path: lightning.pytorch.callbacks.OnExceptionCheckpoint
      init_args:
        dirpath: ckpts/
        filename: on_exception

    # Spike detection - skip batches with loss spikes to stabilize training
    # Useful when dataset may contain corrupted or mislabeled samples
    # - class_path: anime_segmentation.training.callbacks.SpikeDetectionCallback
    #   init_args:
    #     mode: min                    # 'min' or 'max' - direction to detect spikes
    #     window: 10                   # Window size for running statistics
    #     warmup: 1                    # Warmup batches before detection starts
    #     rtol: 2.0                    # Relative tolerance (skip if loss > rtol * running_mean)
    #     finite_only: true            # Also skip NaN/Inf losses

    # Device stats monitor - log GPU/CPU memory usage
    # Useful for debugging memory issues and optimizing batch size
    # - class_path: lightning.pytorch.callbacks.DeviceStatsMonitor
    #   init_args:
    #     cpu_stats: null              # null=auto, true=always log CPU, false=never
