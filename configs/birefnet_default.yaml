# BiRefNet Training Configuration
# ================================
#
# Usage:
#   python -m anime_segmentation.training.train fit --config configs/birefnet_default.yaml
#
# Override settings on command line:
#   python -m anime_segmentation.training.train fit \
#       --config configs/birefnet_default.yaml \
#       --trainer.max_epochs 200 \
#       --data.batch_size 16

seed_everything: 42

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  max_epochs: 120
  accelerator: auto
  devices: auto
  precision: bf16-mixed
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  log_every_n_steps: 50
  check_val_every_n_epoch: 1

  # Logging
  logger:
    class_path: lightning.pytorch.loggers.CSVLogger
    init_args:
      save_dir: ckpts/
      name: logs

# =============================================================================
# Model Configuration
# =============================================================================
model:
  # Backbone
  bb_name: convnext_atto
  bb_pretrained: true

  # Decoder architecture
  out_ref: true
  ms_supervision: true
  dec_ipt: true                    # Decoder input projection
  dec_ipt_split: true              # Split mode for input projection
  cxt_num: 3                       # Context feature count (0-3)
  mul_scl_ipt: cat                 # Multi-scale input fusion: "", "add", "cat"
  dec_att: ASPPDeformable          # Decoder attention: "", "ASPP", "ASPPDeformable"
  squeeze_block: BasicDecBlk_x1    # Squeeze block: "", "BasicDecBlk_x1", "ResBlk_x4"
  dec_blk: BasicDecBlk             # Decoder block type: "BasicDecBlk", "ResBlk"
  lat_blk: BasicLatBlk             # Lateral block type: "BasicLatBlk"
  dec_channels_inter: fixed        # Decoder intermediate channels: "fixed", "adap"
  use_norm: true                   # Use normalization layers

  # Auxiliary classification (disabled by default)
  # auxiliary_classification: true
  # num_classes: 225  # Required when auxiliary_classification is true

  # Activation (default: ReLU)
  # act_layer: gelu  # relu, gelu, swish
  # act_kwargs:
  #   inplace: true

  # Optimizer - any torch.optim optimizer can be used
  # Examples:
  #   torch.optim.Adam, torch.optim.AdamW, torch.optim.SGD, torch.optim.RMSprop
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 0.01

  # Scheduler - any torch.optim.lr_scheduler can be used (or set to null)
  # Examples:
  #   torch.optim.lr_scheduler.CosineAnnealingLR
  #   torch.optim.lr_scheduler.StepLR
  #   torch.optim.lr_scheduler.MultiStepLR
  #   torch.optim.lr_scheduler.OneCycleLR (set scheduler_interval: step)
  scheduler:
    class_path: torch.optim.lr_scheduler.CosineAnnealingLR
    init_args:
      T_max: 120 # Should match trainer.max_epochs
      eta_min: 1e-6
  scheduler_interval: epoch # 'epoch' or 'step'

  # Loss weights
  lambdas_pix:
    bce: 30.0
    iou: 0.5
    ssim: 10.0
    # Additional loss options (set to 0.0 to disable):
    # iou_patch: 0.5    # Patch-based IoU loss
    # mae: 30.0         # Mean Absolute Error
    # mse: 30.0         # Mean Squared Error
    # reg: 100.0        # Regularization
    # cnt: 5.0          # Contour loss
    # structure: 5.0    # Structure loss
  lambdas_cls:
    ce: 5.0

  # torch.compile settings (optional)
  # compile: true
  # compile_mode: default           # default, reduce-overhead, max-autotune, max-autotune-no-cudagraphs
  # compile_fullgraph: false        # Compile as a single graph
  # compile_dynamic: null           # null=auto, true=dynamic shapes, false=static shapes
  # compile_backend: inductor       # Backend: inductor, eager, aot_eager, etc.

# =============================================================================
# Data Configuration
# =============================================================================
data:
  data_root: DIS5K # REQUIRED: Change this to your dataset path
  training_sets:
    - DIS-TR # Example: DIS5K training set
  validation_sets:
    - DIS-VD # Example: DIS5K validation set
  test_sets: []
  size: [1024, 1024]
  batch_size: 8
  num_workers: 4
  pin_memory: true

  # Augmentation settings
  hflip_prob: 0.5
  rotation_degrees: 10.0
  color_jitter: true
  color_jitter_brightness: 0.2
  color_jitter_contrast: 0.2
  color_jitter_saturation: 0.2
  color_jitter_hue: 0.1

# =============================================================================
# Callbacks
# =============================================================================
checkpoint:
  dirpath: ckpts/
  filename: "epoch_{epoch}"
  save_top_k: 3
  monitor: val/loss
  mode: min
  save_last: true

lr_monitor:
  logging_interval: epoch

finetune:
  finetune_last_epochs: -40 # Start fine-tuning 40 epochs before end

early_stopping:
  monitor: val/loss
  patience: 30
  mode: min

visualization:
  num_samples: 4
  log_every_n_epochs: 1
  max_resolution: 512  # Max resolution for visualization (null to keep original)

backbone_freeze:
  unfreeze_at_epoch: 10
  backbone_lr_scale: 0.1

accumulate_grad:
  scheduling:
    0: 4 # Accumulate 4 steps for first 10 epochs
    10: 1 # No accumulation after epoch 10
